{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "## Introduction\n",
    "\"A decision tree is a flowchart-like structure in which each internal node represents a test of an attribute, each branch represents an outcome of that test and each leaf node represents class label (a decision taken after testing all attributes in the path from the root to the leaf). Each path from the root to a leaf can also be represented as a classification rule.\"  \n",
    "[Wikipedia: Decision Tree](https://en.wikipedia.org/wiki/Decision_tree)  \n",
    "\n",
    "## Weather Example\n",
    "The weather example from Witten / Eibe determines whether to play tennis on a given day, or not. We implement a basic version of the ID3 algorithm to create a decision tree that allows to predict new instances based on the earlier measurements.\n",
    "\n",
    "## Algorithm\n",
    "The ID3 algorithm uses a divide and conquer top-down approach that works as follows:\n",
    "\n",
    "1. Choose the best attribute as the node. Create a branch for each possible attribute value\n",
    "2. Part the instances into subsets. One for each branch from the root node\n",
    "3. Repeat steps 1 and 2 recursively for each branch, only the instances belonging to the respective branch be considered. \n",
    "Stop if all instances belong to the same class\n",
    "\n",
    "\n",
    "<img src=\"Decision_Tree_Weather.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Play', 'Outlook', 'Temp', 'Humidity', 'Windy')\n",
      "[('No', 'Sunny', 'Hot', 'High', 'False'),\n",
      " ('No', 'Sunny', 'Hot', 'High', 'True'),\n",
      " ('Yes', 'Overcast', 'Hot', 'High', 'False'),\n",
      " ('Yes', 'Rain', 'Mild', 'High', 'False'),\n",
      " ('Yes', 'Rain', 'Cool', 'Normal', 'False'),\n",
      " ('No', 'Rain', 'Cool', 'Normal', 'True'),\n",
      " ('Yes', 'Overcast', 'Cool', 'Normal', 'True'),\n",
      " ('No', 'Sunny', 'Mild', 'High', 'False'),\n",
      " ('Yes', 'Sunny', 'Cool', 'Normal', 'False'),\n",
      " ('Yes', 'Rain', 'Mild', 'Normal', 'False'),\n",
      " ('Yes', 'Sunny', 'Mild', 'Normal', 'True'),\n",
      " ('Yes', 'Overcast', 'Mild', 'High', 'True'),\n",
      " ('Yes', 'Overcast', 'Hot', 'Normal', 'False'),\n",
      " ('No', 'Rain', 'Mild', 'High', 'True')]\n"
     ]
    }
   ],
   "source": [
    "attribute_names = (\"Play\", \"Outlook\", \"Temp\", \"Humidity\", \"Windy\")\n",
    "\n",
    "data = [(\"No\", \"Sunny\", \"Hot\", \"High\", \"False\"),\n",
    "        (\"No\", \"Sunny\", \"Hot\", \"High\", \"True\"),\n",
    "        (\"Yes\", \"Overcast\", \"Hot\", \"High\", \"False\"),\n",
    "        (\"Yes\", \"Rain\", \"Mild\", \"High\", \"False\"),\n",
    "        (\"Yes\", \"Rain\", \"Cool\", \"Normal\", \"False\"),\n",
    "        (\"No\", \"Rain\", \"Cool\", \"Normal\", \"True\"),\n",
    "        (\"Yes\", \"Overcast\", \"Cool\", \"Normal\", \"True\"),\n",
    "        (\"No\", \"Sunny\", \"Mild\", \"High\", \"False\"),\n",
    "        (\"Yes\", \"Sunny\", \"Cool\", \"Normal\", \"False\"),\n",
    "        (\"Yes\", \"Rain\", \"Mild\", \"Normal\", \"False\"),\n",
    "        (\"Yes\", \"Sunny\", \"Mild\", \"Normal\", \"True\"),\n",
    "        (\"Yes\", \"Overcast\", \"Mild\", \"High\", \"True\"),\n",
    "        (\"Yes\", \"Overcast\", \"Hot\", \"Normal\", \"False\"),\n",
    "        (\"No\", \"Rain\", \"Mild\", \"High\", \"True\")]\n",
    "\n",
    "new_data = (\"?\", \"Rain\", \"Mild\", \"Normal\", \"False\")\n",
    "\n",
    "pprint(attribute_names)\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "## Choosing the best attribute to split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(instances, class_index=0, value_name=None):\n",
    "    '''Calculate the entropy of attribute in position class_index for the list of instances.'''\n",
    "    num_instances = len(instances)\n",
    "\n",
    "    ## there is no uncertainty if there are at most 1 instance\n",
    "    if num_instances <= 1:\n",
    "        return 0\n",
    "\n",
    "    ## instantiates a dict with key: 0\n",
    "    value_counts = defaultdict(int)\n",
    "\n",
    "    for instance in instances:\n",
    "        # defaultdict creates a new key/value pair for every value in\n",
    "        # instance and increments it starting from zero\n",
    "        value_counts[instance[class_index]] += 1\n",
    "    \n",
    "    num_values = len(value_counts)\n",
    "\n",
    "    ## if the value of every instance is the same there is no uncertainty\n",
    "    if num_values <= 1:\n",
    "        return 0\n",
    "    \n",
    "    attribute_entropy = 0.0\n",
    "    \n",
    "    ## Calculate the attribute_entropy based on all the entries in value_counts.\n",
    "    ## Iterate over value_counts, calculate the probability and then determine the entropy for that value.\n",
    "    ## Combine child_entropy for all values to determine the overall entropy\n",
    "    \n",
    "    ## value_counts looks like this after the first run:\n",
    "    ## {'No': 5, 'Yes': 9}\n",
    "    \n",
    "    ## you can calculate entropy for 1 child attribute as follows \n",
    "    ## child_entropy = value_probability * math.log(value_probability, 2)\n",
    "    \n",
    "    for value in value_counts:\n",
    "        value_probability = value_counts[value] / num_instances\n",
    "        child_entropy = value_probability * math.log(value_probability, 2)\n",
    "        attribute_entropy -= child_entropy\n",
    "    ##    \n",
    "    return attribute_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Entropy: 0.9402859586706309\n",
      "Your Entropy:     0.9402859586706309\n"
     ]
    }
   ],
   "source": [
    "## Test the entropy function\n",
    "\n",
    "print('Expected Entropy: 0.9402859586706309')\n",
    "print('Your Entropy:    ', entropy(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(instances, parent_index, class_index=0):\n",
    "    '''Return the information gain of splitting the instances based on the attribute parent_index'''\n",
    "    \n",
    "    \n",
    "    ## determine the parent_entropy based on the input instances\n",
    "    parent_entropy = entropy(instances, class_index)\n",
    "    ##\n",
    "    \n",
    "    child_instances = defaultdict(list)\n",
    "    '''\n",
    "    append the instances for the given parent_index to the dict child_instances\n",
    "    the structure should look like this:\n",
    "    {key: [list with (instance tuples)]}\n",
    "    \n",
    "    {'Overcast': [('Yes', 'Overcast', 'Hot', 'High', 'False'), \n",
    "                ('Yes', 'Overcast', 'Cool', 'Normal', 'True'), \n",
    "                ('Yes', 'Overcast', 'Mild', 'High', 'True'), \n",
    "                ('Yes', 'Overcast', 'Hot', 'Normal', 'False')], \n",
    "    'Sunny': [('No', 'Sunny', 'Hot', 'High', 'False'), \n",
    "            ('No', 'Sunny', 'Hot', 'High', 'True'), \n",
    "            ('No', 'Sunny', 'Mild', 'High', 'False'), \n",
    "            ('Yes', 'Sunny', 'Cool', 'Normal', 'False'), \n",
    "            ('Yes', 'Sunny', 'Mild', 'Normal', 'True')], \n",
    "    'Rain': [('Yes', 'Rain', 'Mild', 'High', 'False'), \n",
    "            ('Yes', 'Rain', 'Cool', 'Normal', 'False'), \n",
    "            ('No', 'Rain', 'Cool', 'Normal', 'True'), \n",
    "            ('Yes', 'Rain', 'Mild', 'Normal', 'False'), \n",
    "            ('No', 'Rain', 'Mild', 'High', 'True')]}\n",
    "    \n",
    "    '''\n",
    "    for instance in instances:\n",
    "        child_instances[instance[parent_index]].append(instance)\n",
    "\n",
    "    \n",
    "    children_entropy = 0.0\n",
    "    num_instances = len(instances)\n",
    "    \n",
    "    for child_value in child_instances:\n",
    "        child_probability = len(child_instances[child_value]) / num_instances\n",
    "        children_entropy += child_probability * entropy(child_instances[child_value], class_index, child_value)\n",
    "    \n",
    "    return parent_entropy - children_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Result\n",
      "Gain Index Attribute\n",
      "0.247 1 Outlook\n",
      "0.152 3 Humidity\n",
      "0.048 4 Windy\n",
      "0.029 2 Temp\n",
      "\n",
      "Your result\n",
      "Gain Index Attribute\n",
      "0.247   1 Outlook\n",
      "0.152   3 Humidity\n",
      "0.048   4 Windy\n",
      "0.029   2 Temp\n"
     ]
    }
   ],
   "source": [
    "## Test information_gain\n",
    "\n",
    "## list comprehension instead of for-loop\n",
    "## the following for-loop would do the same\n",
    "# information_gain_indexes = []\n",
    "# for i in range(1, len(attribute_names)):\n",
    "#    information_gain_indexes.append((information_gain(data, i), i))\n",
    "    \n",
    "information_gain_indexes = [(information_gain(data, i), i) for i in range(1, len(attribute_names))]\n",
    "\n",
    "\n",
    "## sort descending with reverse=True\n",
    "## if not specified otherwise the function sorts based on the first element of a tupel\n",
    "sorted_information_gain_indexes = sorted(information_gain_indexes, reverse=True)\n",
    "\n",
    "\n",
    "print('Expected Result')\n",
    "print('Gain', 'Index', 'Attribute')\n",
    "print(0.247, 1, 'Outlook')\n",
    "print(0.152, 3, 'Humidity')\n",
    "print(0.048, 4, 'Windy')\n",
    "print(0.029, 2, 'Temp')\n",
    "print()\n",
    "\n",
    "print('Your result')\n",
    "print(\"Gain\", \"Index\", \"Attribute\")\n",
    "for gain, i in sorted_information_gain_indexes:\n",
    "    print('{:5.3f}  {:2} {}'.format(gain, i, attribute_names[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_attribute_index(instances, candidate_attribute_indexes, class_index=0):\n",
    "    '''Return the index of the attribute that will provide the greatest information gain\n",
    "    if instances were partitioned based on that attribute'''\n",
    "    \n",
    "    ## calculate the information_gain for all the attributes in candidate_attribute_indexes\n",
    "    ## return the index of the attribute with the highest gain\n",
    "    gains_and_indexes = sorted([(information_gain(instances, i), i) for i in candidate_attribute_indexes],\n",
    "                               reverse=True)\n",
    "    return gains_and_indexes[0][1]\n",
    "    ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected result: 1\n",
      "Your result:     1\n"
     ]
    }
   ],
   "source": [
    "## Test choose_best_attribute_index\n",
    "\n",
    "candidate_attribute_indexes = [i for i in range(len(data[0])) if i != 0]\n",
    "\n",
    "best_attribute_index = choose_best_attribute_index(data, candidate_attribute_indexes)\n",
    "print('Expected result: 1')\n",
    "print('Your result:    ', best_attribute_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_instances(instances, attribute_index):\n",
    "    '''Returns a list of dictionaries, splitting a list of instances\n",
    "        according to their values of a specified attribute index\n",
    "\n",
    "    The key of each dictionary is a distinct value of attribute_index,\n",
    "    and the value of each dictionary is a list representing\n",
    "       the subset of instances that have that value for the attribute\n",
    "    '''\n",
    "    partitions = defaultdict(list)\n",
    "    for instance in instances:\n",
    "        partitions[instance[attribute_index]].append(instance)\n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>,\n",
      "            {'Overcast': [('Yes', 'Overcast', 'Hot', 'High', 'False'),\n",
      "                          ('Yes', 'Overcast', 'Cool', 'Normal', 'True'),\n",
      "                          ('Yes', 'Overcast', 'Mild', 'High', 'True'),\n",
      "                          ('Yes', 'Overcast', 'Hot', 'Normal', 'False')],\n",
      "             'Rain': [('Yes', 'Rain', 'Mild', 'High', 'False'),\n",
      "                      ('Yes', 'Rain', 'Cool', 'Normal', 'False'),\n",
      "                      ('No', 'Rain', 'Cool', 'Normal', 'True'),\n",
      "                      ('Yes', 'Rain', 'Mild', 'Normal', 'False'),\n",
      "                      ('No', 'Rain', 'Mild', 'High', 'True')],\n",
      "             'Sunny': [('No', 'Sunny', 'Hot', 'High', 'False'),\n",
      "                       ('No', 'Sunny', 'Hot', 'High', 'True'),\n",
      "                       ('No', 'Sunny', 'Mild', 'High', 'False'),\n",
      "                       ('Yes', 'Sunny', 'Cool', 'Normal', 'False'),\n",
      "                       ('Yes', 'Sunny', 'Mild', 'Normal', 'True')]})\n"
     ]
    }
   ],
   "source": [
    "partitions = split_instances(data, 1)\n",
    "pprint(partitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find the majority value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_value(instances, class_index=0):\n",
    "    '''Return the most frequent value of class_index in instances\n",
    "       It may be easier to use the Counter that is already imported\n",
    "       https://docs.python.org/3.1/library/collections.html#collections.Counter\n",
    "    '''\n",
    "    class_counts = Counter([instance[class_index] for instance in instances])\n",
    "    return class_counts.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected result: Yes\n",
      "Your result:     Yes\n"
     ]
    }
   ],
   "source": [
    "## Test majority_value\n",
    "print('Expected result: Yes')\n",
    "print('Your result:    ', majority_value(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decision_tree(instances,\n",
    "                         candidate_attribute_indexes=None,\n",
    "                         class_index=0,\n",
    "                         default_class=None):\n",
    "    '''Returns a new decision tree trained on a list of instances.\n",
    "\n",
    "    The tree is constructed by recursively selecting and splitting instances based on\n",
    "    the highest information_gain of the candidate_attribute_indexes.\n",
    "\n",
    "    The class label is found in position class_index.\n",
    "\n",
    "    The default_class is the majority value for the current node's parent in the tree.\n",
    "\n",
    "    Derived from the simplified ID3 algorithm presented in Building Decision Trees in Python\n",
    "        by Christopher Roach,\n",
    "    http://www.onlamp.com/pub/a/python/2006/02/09/ai_decision_trees.html?page=3\n",
    "    '''\n",
    "\n",
    "    # if no candidate_attribute_indexes are provided,\n",
    "    # assume that we will use all but the target_attribute_index\n",
    "    # Note that None != [],\n",
    "    # as an empty candidate_attribute_indexes list is a recursion stopping condition\n",
    "    if candidate_attribute_indexes is None:\n",
    "        candidate_attribute_indexes = [i\n",
    "                                       for i in range(len(instances[0]))\n",
    "                                       if i != class_index]\n",
    "        # Note: do not use candidate_attribute_indexes.remove(class_index)\n",
    "        # as this would destructively modify the argument,\n",
    "        # causing problems during recursive calls\n",
    "\n",
    "    class_labels_and_counts = Counter([instance[class_index] for instance in instances])\n",
    "\n",
    "    # If the dataset is empty or the candidate attributes list is empty,\n",
    "    # return the default value\n",
    "    if not instances or not candidate_attribute_indexes:\n",
    "        return default_class\n",
    "\n",
    "    # If all the instances have the same class label, return that class label\n",
    "    elif len(class_labels_and_counts) == 1:\n",
    "        class_label = class_labels_and_counts.most_common(1)[0][0]\n",
    "        return class_label\n",
    "    else:\n",
    "        default_class = majority_value(instances, class_index)\n",
    "\n",
    "        # Choose the next best attribute index to best classify the instances\n",
    "        best_index = choose_best_attribute_index(\n",
    "            instances, candidate_attribute_indexes, class_index)\n",
    "\n",
    "        # Create a new decision tree node with the best attribute index\n",
    "        # and an empty dictionary object (for now)\n",
    "        tree = {(best_index, attribute_names[best_index]): {}}\n",
    "\n",
    "        # Create a new decision tree sub-node (branch) for each of the values\n",
    "        # in the best attribute field\n",
    "        partitions = split_instances(instances, best_index)\n",
    "\n",
    "        # Remove that attribute from the set of candidates for further splits\n",
    "        remaining_candidate_attribute_indexes = [i for i in candidate_attribute_indexes\n",
    "                                                 if i != best_index]\n",
    "        \n",
    "        for attribute_value in partitions:\n",
    "            # Create a subtree for each value of the the best attribute\n",
    "            subtree = create_decision_tree(\n",
    "                partitions[attribute_value],\n",
    "                remaining_candidate_attribute_indexes,\n",
    "                class_index,\n",
    "                default_class)\n",
    "\n",
    "            # Add the new subtree to the empty dictionary object\n",
    "            # in the new tree/node we just created\n",
    "            tree[best_index, attribute_names[best_index]][attribute_value] = subtree\n",
    "\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(1, 'Outlook'): {'Overcast': 'Yes',\n",
      "                  'Rain': {(4, 'Windy'): {'False': 'Yes', 'True': 'No'}},\n",
      "                  'Sunny': {(3, 'Humidity'): {'High': 'No', 'Normal': 'Yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "tree = create_decision_tree(data)\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Play', 'Outlook', 'Temp', 'Humidity', 'Windy')\n",
      "('?', 'Rain', 'Mild', 'Normal', 'False')\n"
     ]
    }
   ],
   "source": [
    "print(attribute_names)\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, instance, default_class=None):\n",
    "    '''Returns a classification label for instance, given a decision tree'''\n",
    "    \n",
    "    if not tree:  # if the node is empty, return the default class\n",
    "        return default_class\n",
    "    \n",
    "    if not isinstance(tree, dict):  # if the node is a leaf, return its class label\n",
    "        return tree\n",
    "    \n",
    "    attribute_index = list(tree.keys())[0]  # using list(dict.keys()) for Python 3 compatibility\n",
    "    attribute_values = list(tree.values())[0]\n",
    "    instance_attribute_value = instance[attribute_index[0]]\n",
    "    \n",
    "    if instance_attribute_value not in attribute_values:  # this value was not in training data\n",
    "        return default_class\n",
    "    \n",
    "    # recursively traverse the subtree (branch) associated with instance_attribute_value\n",
    "    return classify(attribute_values[instance_attribute_value], instance, default_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should he play today? The answer is Yes\n"
     ]
    }
   ],
   "source": [
    "print(\"Should he play today? The answer is\", classify(tree, new_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_accuracy(tree, instances, class_index=0, print_predictions=False):\n",
    "    '''Returns the accuracy of classifying test_instances with tree,\n",
    "    where the class label is in position class_index'''\n",
    "    \n",
    "    ## create a list predicted_labels that contains a prediction for every instance in instances\n",
    "    predicted_labels = [classify(tree, instance)\n",
    "                        for instance in instances]\n",
    "    \n",
    "    ## create a list actual_labels that contains the real class value for every instance in instances\n",
    "    actual_labels = [instance[class_index]\n",
    "                     for instance in instances]\n",
    "\n",
    "    ## compare the predicted and actual labels for every instance and calculate the accuracy of the predictions\n",
    "    counts = Counter([x == y\n",
    "                      for x, y in zip(predicted_labels, actual_labels)])\n",
    "    \n",
    "    ## print your result\n",
    "    print(\"Accuracy:\", counts[True] / len(instances))\n",
    "    \n",
    "    if print_predictions:\n",
    "        for i in range(0, len(instances)):\n",
    "            predicted_label = predicted_labels[i]\n",
    "            actual_label = actual_labels[i]\n",
    "            print('predicted:', predicted_label, 'actual:', actual_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_analysis(nr_of_train_inst, print_predictions=False):\n",
    "    nr_of_test_inst = len(data) - nr_of_train_inst\n",
    "    \n",
    "    ## split the data into two lists training_instances and test_instances based on the parameter nr_of_train_inst\n",
    "    training_instances = data[:-nr_of_test_inst]\n",
    "    test_instances = data[-nr_of_test_inst:]\n",
    "    ##\n",
    "    \n",
    "    ## build a decision tree based on the training instances\n",
    "    tree = create_decision_tree(training_instances)\n",
    "    ##\n",
    "    \n",
    "    print(\"Result with\", nr_of_train_inst, \"training and\", nr_of_test_inst, \"test instances\")\n",
    "    \n",
    "    ## call the function classification_accuracy and test the tree with the test_instances\n",
    "    classification_accuracy(tree, test_instances, print_predictions=print_predictions)\n",
    "    ##\n",
    "    \n",
    "    pprint(tree)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result with 6 training and 8 test instances\n",
      "Accuracy: 0.75\n",
      "{(1, 'Outlook'): {'Overcast': 'Yes',\n",
      "                  'Rain': {(4, 'Windy'): {'False': 'Yes', 'True': 'No'}},\n",
      "                  'Sunny': 'No'}}\n",
      "\n",
      "Result with 10 training and 4 test instances\n",
      "Accuracy: 1.0\n",
      "{(1, 'Outlook'): {'Overcast': 'Yes',\n",
      "                  'Rain': {(4, 'Windy'): {'False': 'Yes', 'True': 'No'}},\n",
      "                  'Sunny': {(3, 'Humidity'): {'High': 'No', 'Normal': 'Yes'}}}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## call the function test_analysis with different numbers of training instances and determine a good split\n",
    "## between training and test instances\n",
    "## if you call the function with print_predictions=True you will see the comparison of predictions and actual labels\n",
    "\n",
    "test_analysis(6)\n",
    "test_analysis(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Further Reading\n",
    "\n",
    "[Andy Giese Blog](https://gieseanw.wordpress.com/2012/03/03/decision-tree-learning/)  \n",
    "[Python for Data Science - 3 Basic Concepts](https://github.com/gumption/Python_for_Data_Science/blob/74bea110cbe47ebecc4d58e32039847a66db5317/3_Python_Basic_Concepts.ipynb)  \n",
    "[Python for Data Science - 4 Decision Trees](https://github.com/gumption/Python_for_Data_Science/blob/74bea110cbe47ebecc4d58e32039847a66db5317/4_Python_Simple_Decision_Tree.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
