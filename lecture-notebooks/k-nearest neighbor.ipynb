{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\"In pattern recognition, the k-Nearest Neighbors algorithm (or k-NN for short) is a non-parametric method used for classification and regression. In both cases, the input consists of the k closest training examples in the feature space. The output depends on whether k-NN is used for classification or regression:\n",
    "\n",
    "+ In k-NN classification, the output is a class membership. An object is classified by a majority vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor.\n",
    "+ In k-NN regression, the output is the property value for the object. This value is the average of the values of its k nearest neighbors.\n",
    "\n",
    "k-NN is a type of instance-based learning, or lazy learning, where the function is only approximated locally and all computation is deferred until classification. The k-NN algorithm is among the simplest of all machine learning algorithms.\" [Wikipedia](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)\n",
    "\n",
    "<img src=\"KnnClassification.svg\">  \n",
    "\n",
    "The following steps are necessary to implement a k-nearest neighbor algorithm:\n",
    "+ process dataset\n",
    "+ calculate similarity\n",
    "+ locate nearest neighbors\n",
    "+ classification of new instance\n",
    "+ compute accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "This example is based on the work of Jason Brownlee. Please see his blog article in the further reading section. I ported the example from python 2.x to python 3.x, added some comments and intermediate results for clarification.\n",
    "\n",
    "\"The problem is comprised of 150 observations of iris flowers from three different species. There are 4 measurements of given flowers: sepal length, sepal width, petal length and petal width, all in the same unit of centimeters. The predicted attribute is the species, which is one of setosa, versicolor or virginica.\n",
    "\n",
    "It is a standard dataset where the species is known for all instances. As such we can split the data into training and test datasets and use the results to evaluate our algorithm implementation. Good classification accuracy on this problem is above 90% correct, typically 96% or better.\"\n",
    "\n",
    "# Exercises\n",
    "\n",
    "## load a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    \n",
    "    ## Create a list to store your cleaned data\n",
    "    result = []\n",
    "    \n",
    "    return result \n",
    "    \n",
    "            ## append the cleaned row to your output list\n",
    "            \n",
    "    \n",
    "    ## return your result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: [5.1, 3.5, 1.4, 0.2, 'setosa']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-77127e0ed4d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/iris2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Solution:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'setosa'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Your solution:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('data/iris2.csv')\n",
    "print('Solution:', [5.1, 3.5, 1.4, 0.2, 'setosa'])\n",
    "print('Your solution:', dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate similarity\n",
    "The similarity of two instances is derived by the distance between them. There are several different methods to calculate the distance.  \n",
    "The \"ordinary\" straight line distance between two points is called the euclidean distance.\n",
    "\n",
    "### Euclidean distance\n",
    "The formula to compute the euclidean distance in n-dimensional space is:  \n",
    "$ {\\sqrt{\\sum_i^n({q_i - p_i})^2 }}$  \n",
    "+ calculate the distance of the different axis\n",
    "+ sum the different distances\n",
    "+ square root of the intermediate result\n",
    "\n",
    "For more information see [Wikipedia](https://en.wikipedia.org/wiki/Euclidean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(instance1, instance2):\n",
    "    distance = 0\n",
    "    \n",
    "    ## returns the square root of the calculated sum of squared distances \n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: 5.196152422706632\n",
      "Your Solution:  0.0\n"
     ]
    }
   ],
   "source": [
    "## euclidean distance\n",
    "data1 = [1, 2, 3, 'a']\n",
    "data2 = [4, 5, 6, 'b']\n",
    "\n",
    "distance = euclidean_distance(data1, data2)\n",
    "print('Solution:', 5.196152422706632)\n",
    "print('Your Solution: ', distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    result = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        ## uses csv.reader() to process the input file and create a list\n",
    "        lines = csv.reader(csvfile)\n",
    "        raw_dataset = list(lines)\n",
    "        \n",
    "        ## range(len()) to get the row index, not the row itself\n",
    "        for row in range(len(raw_dataset)):\n",
    "            ## converts the values from string to float, excludes class label\n",
    "            ## range excludes the specified value, range 4 is from 0 to 3\n",
    "            for col in range(4):\n",
    "                floatie = float(raw_dataset[row][col])\n",
    "                raw_dataset[row][col] = floatie\n",
    "\n",
    "            result.append(raw_dataset[row])\n",
    "            \n",
    "        return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(instance1, instance2):\n",
    "    distance = 0\n",
    "    for x in range(len(instance1) - 1):\n",
    "        ## distance = (2-5)² + (3-6)² + (4-7)²\n",
    "        distance += pow((instance1[x] - instance2[x]), 2)\n",
    "    \n",
    "    ## returns the square root of the calculated sum of squared distances \n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "## Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename, split):\n",
    "    \n",
    "    ## create empty lists for training and test set\n",
    "    training_set = []\n",
    "    test_set = []\n",
    "    \n",
    "    with open(filename, 'r') as csvfile:\n",
    "        ## uses csv.reader() to process the input file and create a list\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "        \n",
    "        for x in range(len(dataset)):\n",
    "            ## converts the values from string to float, excludes class label\n",
    "            ## range excludes the specified value, range 4 is from 0 to 3\n",
    "            for y in range(4):\n",
    "                dataset[x][y] = float(dataset[x][y])\n",
    "\n",
    "            ## appends to training or test set according to the specified split\n",
    "            if random.random() < split:\n",
    "                training_set.append(dataset[x])\n",
    "            else:\n",
    "                test_set.append(dataset[x])\n",
    "\n",
    "        return training_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances:  130\n",
      "Test instances:  20\n",
      "Example Training instance:  [5.1, 3.5, 1.4, 0.2, 'setosa']\n",
      "Example Test instance:  [4.9, 3.0, 1.4, 0.2, 'setosa']\n"
     ]
    }
   ],
   "source": [
    "## load_dataset, adjust the split parameter to change the ratio from training and test set\n",
    "split = 0.9\n",
    "\n",
    "training_set, test_set = load_dataset('iris2.csv', split)\n",
    "print('Training instances: ', len(training_set))\n",
    "print('Test instances: ', len(test_set))\n",
    "print('Example Training instance: ', training_set[0])\n",
    "print('Example Test instance: ', test_set[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate nearest neighbors\n",
    "As the k-nearest neighbor algorithm is a lazy learner most of the computation will be done while classification.  \n",
    "The function computes the distance from the test instance to all the training instances and returns the k nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(training_set, test_instance, k):\n",
    "    distances = []\n",
    "    \n",
    "    for x in range(len(training_set)):\n",
    "        ## finds the distance from the test instance to all the training instances\n",
    "        dist = euclidean_distance(test_instance, training_set[x])\n",
    "        distances.append((training_set[x], dist))\n",
    "    \n",
    "    #sorts ascending, smallest distance comes first\n",
    "    # ([2,2,2,'a'], dist)\n",
    "    distances.sort(key=itemgetter(1))\n",
    "    neighbors = []\n",
    "    \n",
    "    for x in range(k):\n",
    "        # returns k nearest neighbors\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 4, 4, 'b']]\n"
     ]
    }
   ],
   "source": [
    "## get neighbors, adjust k to calculate k-neighbors\n",
    "k = 1\n",
    "\n",
    "train_set = [[2, 2, 2, 'a'], [4, 4, 4, 'b']]\n",
    "test_instance = [5, 5, 5, 'b']\n",
    "\n",
    "neighbors = get_neighbors(train_set, test_instance, k)\n",
    "print(neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of new instance\n",
    "The classification is based on a majority vote of all the neighbors found in the last step.  \n",
    "Every neighbor will vote for the assignment of its own class. Therefore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification(neighbors):\n",
    "    class_votes = defaultdict(int)\n",
    "    \n",
    "    ## for all neighbors the response is each own class label\n",
    "    for neighbor in neighbors:\n",
    "        ## negative indexing indicates the last element, the class label of an instance\n",
    "        response = neighbor[-1]\n",
    "        class_votes[response] += 1\n",
    "    \n",
    "    ## sorts all the class votes descending by vote count\n",
    "    ## sorted_votes has the format ('class_name', count)\n",
    "    sorted_votes = sorted(class_votes.items(), key=itemgetter(1), reverse=True)\n",
    "    \n",
    "    ## returns just the class label \n",
    "    return sorted_votes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "## get classification\n",
    "neighbors = [[1, 1, 1, 'a'], [2, 2, 2, 'a'], [3, 3, 3, 'b']]\n",
    "response = get_classification(neighbors)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute accuracy\n",
    "To assess the quality of the output we calculate the accuracy. Accuracy is returned in percent of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(test_set, predictions):\n",
    "    correct = 0\n",
    "\n",
    "    for x in range(len(test_set)):\n",
    "        ## negative indexing; -1 targets the last element\n",
    "        if test_set[x][-1] == predictions[x]:\n",
    "            correct += 1\n",
    "    return (correct / len(test_set)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "## get accuracy\n",
    "test_set = [[1,1,1,'a'], [2,2,2,'a'], [3,3,3,'b']]\n",
    "predictions = ['a', 'a', 'a']\n",
    "accuracy = get_accuracy(test_set, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances:  99\n",
      "Test instances:  51\n",
      "Accuracy:  96.07843137254902 %\n"
     ]
    }
   ],
   "source": [
    "## parameters, adjust and see how the result changes\n",
    "split = 0.66\n",
    "k = 3\n",
    "\n",
    "training_set, test_set = load_dataset('iris2.csv', split)\n",
    "print('Training instances: ', len(training_set))\n",
    "print('Test instances: ', len(test_set))\n",
    "\n",
    "## generate predictions\n",
    "predictions=[]\n",
    "\n",
    "for test_inst in test_set:\n",
    "    neighbors = get_neighbors(training_set, test_inst, k)\n",
    "    result = get_classification(neighbors)\n",
    "    predictions.append(result)\n",
    "    #print('> predicted=', result, ', actual=', test_inst[-1])\n",
    "\n",
    "accuracy = get_accuracy(test_set, predictions)\n",
    "print('Accuracy: ', accuracy, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "This is a really simple implementation which could still be greatly improved. For example:\n",
    "\n",
    "### Find best k  \n",
    "Write a function that executes the algorithm with different values for k and return the choice with the highest accuracy.\n",
    "\n",
    "### Weighted neighbors  \n",
    "Assigning weights to the neighbors will give the neighbors in close range more influence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further reading\n",
    "+ [Jason Brownlee](http://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/)\n",
    "+ [Natasha Latysheva](https://blog.cambridgecoding.com/2016/01/16/machine-learning-under-the-hood-writing-your-own-k-nearest-neighbour-algorithm/)\n",
    "+ [scikit-learn](http://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html#sphx-glr-auto-examples-neighbors-plot-classification-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
